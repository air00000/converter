import asyncio
import io
import logging
import os
import re
from typing import Iterable, List, Mapping, Optional, Tuple
from urllib.parse import parse_qs, unquote, urlparse

import aiohttp
from aiogram import Bot, Dispatcher, F
from aiogram.enums import ParseMode
from aiogram.exceptions import TelegramBadRequest
from aiogram.filters import Command, CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import BufferedInputFile, Message
from dotenv import load_dotenv


PLACEHOLDER_PATTERN = re.compile(r"\{([a-zA-Z_][\w-]*)\}")
URL_PATTERN = re.compile(r"https?://\S+")


class ConversionStates(StatesGroup):
    input_mask = State()
    output_mask = State()
    lines_per_file = State()
    waiting_file = State()


def _extract_placeholders(mask: str) -> List[str]:
    return [match.group(1) for match in PLACEHOLDER_PATTERN.finditer(mask)]


def _mask_to_regex(mask: str) -> re.Pattern[str]:
    placeholders = list(PLACEHOLDER_PATTERN.finditer(mask))
    if not placeholders:
        raise ValueError("–ú–∞—Å–∫–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö.")

    pattern_parts: List[str] = []
    last_index = 0

    for idx, placeholder in enumerate(placeholders):
        pattern_parts.append(re.escape(mask[last_index : placeholder.start()]))
        name = placeholder.group(1)
        quantifier = ".+" if idx == len(placeholders) - 1 else ".+?"
        pattern_parts.append(f"(?P<{name}>{quantifier})")
        last_index = placeholder.end()

    pattern_parts.append(re.escape(mask[last_index:]))
    pattern = "".join(pattern_parts)
    return re.compile(rf"^{pattern}$")


def _convert_lines(lines: Iterable[str], input_mask: str, output_mask: str) -> List[str]:
    regex = _mask_to_regex(input_mask)
    required_fields = set(_extract_placeholders(output_mask))
    converted: List[str] = []

    for raw_line in lines:
        line = raw_line.strip()
        if not line:
            continue

        match = regex.match(line)
        if not match:
            continue

        values = match.groupdict()

        missing = required_fields.difference(values)
        if missing:
            raise ValueError(
                "–í –≤—ã—Ö–æ–¥–Ω–æ–π –º–∞—Å–∫–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è: " + ", ".join(sorted(missing))
            )

        converted.append(output_mask.format_map(values))

    return converted


def _strip_trailing_punctuation(url: str) -> str:
    return url.rstrip(".,)>]}\n\r")


def _filename_from_headers(headers: Optional[Mapping[str, str]]) -> Optional[str]:
    content_disposition = headers.get("Content-Disposition") if headers else None
    if not content_disposition:
        return None

    match = re.search(r"filename\*=UTF-8''([^;]+)", content_disposition)
    if match:
        return unquote(match.group(1))

    match = re.search(r'filename="?([^";]+)"?', content_disposition)
    if match:
        return match.group(1)

    return None


def _extract_drive_file_id(parsed_url) -> Optional[str]:
    if parsed_url.path.startswith("/file/d/"):
        parts = parsed_url.path.split("/")
        try:
            file_index = parts.index("d") + 1
            return parts[file_index]
        except (ValueError, IndexError):
            return None

    query = parse_qs(parsed_url.query)
    for key in ("id", "fid"):
        if key in query and query[key]:
            return query[key][0]

    path_parts = parsed_url.path.split("/")
    if "uc" in path_parts:
        try:
            idx = path_parts.index("uc")
            if idx + 1 < len(path_parts):
                return path_parts[idx + 1]
        except ValueError:
            pass

    return None


async def _download_google_drive_file(
    session: aiohttp.ClientSession, file_id: str
) -> Tuple[bytes, Optional[str]]:
    download_url = "https://drive.google.com/uc"
    params = {"export": "download", "id": file_id}

    async with session.get(download_url, params=params) as response:
        response.raise_for_status()
        content_type = response.headers.get("Content-Type", "")

        if "text/html" not in content_type:
            content = await response.read()
            filename = _filename_from_headers(response.headers)
            return content, filename or f"google-drive-{file_id}"

        page = await response.text()
        token_match = re.search(r"confirm=([0-9A-Za-z_]+)", page)
        if not token_match:
            raise ValueError(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª –∏–∑ Google Drive. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –¥–æ—Å—Ç—É–ø –ø–æ —Å—Å—ã–ª–∫–µ –æ—Ç–∫—Ä—ã—Ç."
            )

        params["confirm"] = token_match.group(1)

    async with session.get(download_url, params=params) as response:
        response.raise_for_status()
        content = await response.read()
        filename = _filename_from_headers(response.headers)

    return content, filename or f"google-drive-{file_id}"


async def _download_yandex_disk_file(session: aiohttp.ClientSession, public_key: str) -> Tuple[bytes, Optional[str]]:
    api_url = "https://cloud-api.yandex.net/v1/disk/public/resources/download"

    async with session.get(api_url, params={"public_key": public_key}) as meta_response:
        meta_response.raise_for_status()
        meta = await meta_response.json()

    href = meta.get("href")
    if not href:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞.")

    async with session.get(href) as file_response:
        file_response.raise_for_status()
        content = await file_response.read()
        filename = _filename_from_headers(file_response.headers)

    return content, filename


async def _download_file_from_link(url: str) -> Tuple[bytes, Optional[str]]:
    parsed = urlparse(url)
    if parsed.scheme not in {"http", "https"}:
        raise ValueError("–ü–æ—Ö–æ–∂–µ, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç.")

    domain = parsed.netloc.lower()

    async with aiohttp.ClientSession() as session:
        if "drive.google.com" in domain:
            file_id = _extract_drive_file_id(parsed)
            if not file_id:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ñ–∞–π–ª–∞ Google Drive.")
            return await _download_google_drive_file(session, file_id)

        if any(domain.endswith(part) for part in ("yadi.sk", "disk.yandex.ru")):
            return await _download_yandex_disk_file(session, url)

    raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏ –Ω–∞ Google Drive –∏ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫.")


async def handle_start(message: Message, state: FSMContext) -> None:
    await state.clear()
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –º–∞—Å–∫—É —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞.\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "`{protocol}://{domain}:{username}:{password}`",
        parse_mode=ParseMode.MARKDOWN,
    )
    await state.set_state(ConversionStates.input_mask)


async def handle_cancel(message: Message, state: FSMContext) -> None:
    await state.clear()
    await message.answer("–°–±—Ä–æ—Å–∏–ª —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é. –ù–∞–ø–∏—à–∏ /start, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ.")


async def handle_input_mask(message: Message, state: FSMContext) -> None:
    mask = message.text or ""
    try:
        _mask_to_regex(mask)
    except ValueError as exc:
        await message.answer(str(exc))
        return

    await state.update_data(input_mask=mask)
    await state.set_state(ConversionStates.output_mask)
    await message.answer(
        "–û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å –º–∞—Å–∫—É –Ω—É–∂–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–µ –∂–µ –∏–º–µ–Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä: `{username}:{password}`",
        parse_mode=ParseMode.MARKDOWN,
    )


async def handle_output_mask(message: Message, state: FSMContext) -> None:
    mask = message.text or ""
    if not PLACEHOLDER_PATTERN.search(mask):
        await message.answer("–í –º–∞—Å–∫–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö.")
        return

    await state.update_data(output_mask=mask)

    await state.set_state(ConversionStates.lines_per_file)
    await message.answer(
        "–ï—Å–ª–∏ —Ö–æ—á–µ—à—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, –≤–≤–µ–¥–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–∞ –æ–¥–∏–Ω —Ñ–∞–π–ª.\n"
        "–û—Ç–ø—Ä–∞–≤—å 0 –∏–ª–∏ —Å–ª–æ–≤–æ 'skip', —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª.",
    )


async def handle_lines_per_file(message: Message, state: FSMContext) -> None:
    text = (message.text or "").strip().lower()

    if not text:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –∏–ª–∏ 0, —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å.")
        return

    if text in {"skip", "0", "–Ω–µ—Ç", "no"}:
        lines_per_file = 0
    else:
        try:
            lines_per_file = int(text)
        except ValueError:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —á–∏—Å–ª–æ. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.")
            return

        if lines_per_file <= 0:
            lines_per_file = 0

    await state.update_data(lines_per_file=lines_per_file)
    await state.set_state(ConversionStates.waiting_file)
    await message.answer("–û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏ —Ñ–∞–π–ª –≤ –≤–∏–¥–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –Ø –≤–µ—Ä–Ω—É –µ–≥–æ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.")



async def _convert_and_send(message: Message, state: FSMContext, file_content: bytes) -> None:
    data = await state.get_data()
    input_mask = data.get("input_mask")
    output_mask = data.get("output_mask")

    lines_per_file = int(data.get("lines_per_file", 0) or 0)

    if not input_mask or not output_mask:
        await message.answer("–°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å –º–∞—Å–∫–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /start.")
        return

    text = file_content.decode("utf-8", errors="ignore")
    try:
        converted_lines = _convert_lines(text.splitlines(), input_mask, output_mask)
    except ValueError as exc:
        await message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª: {exc}")
        return

    if not converted_lines:
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫–∏, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–æ–¥ –≤—Ö–æ–¥–Ω—É—é –º–∞—Å–∫—É.")
        return

    chunks: List[List[str]]
    if lines_per_file > 0:
        chunks = [
            converted_lines[idx : idx + lines_per_file]
            for idx in range(0, len(converted_lines), lines_per_file)
        ]
    else:
        chunks = [converted_lines]

    if len(chunks) > 1:
        await message.answer(f"–ì–æ—Ç–æ–≤–æ! –†–∞–∑–±–∏–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ {len(chunks)} —Ñ–∞–π–ª–∞(–æ–≤).")

    for idx, chunk in enumerate(chunks, start=1):
        output_bytes = "\n".join(chunk).encode("utf-8")
        filename = "converted.txt" if len(chunks) == 1 else f"converted_part_{idx}.txt"
        output_file = BufferedInputFile(output_bytes, filename=filename)

        try:
            await message.answer_document(
                output_file,
                caption=("–ì–æ—Ç–æ–≤–æ! –í–æ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª." if len(chunks) == 1 else None),
            )
        except TelegramBadRequest:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π —Ñ–∞–π–ª –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.")
            return


    await state.clear()


async def handle_file(message: Message, state: FSMContext, bot: Bot) -> None:
    document = message.document
    if not document:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å —Ñ–∞–π–ª –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç (–Ω–µ –∫–∞–∫ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é).")
        return

    file = await bot.get_file(document.file_id)
    buffer = io.BytesIO()
    await bot.download_file(file.file_path, buffer)
    buffer.seek(0)

    await _convert_and_send(message, state, buffer.read())


async def handle_file_link(message: Message, state: FSMContext) -> None:
    text = (message.text or "").strip()
    match = URL_PATTERN.search(text)
    if not match:
        await message.answer(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–∞–π–ª –≤ Google Drive –∏–ª–∏ –Ω–∞ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–µ."
        )
        return

    url = _strip_trailing_punctuation(match.group(0))

    try:
        file_content, _ = await _download_file_from_link(url)
    except ValueError as exc:
        await message.answer(str(exc))
        return
    except aiohttp.ClientError:
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å –¥–æ–∫—É–º–µ–Ω—Ç.")
        return

    await _convert_and_send(message, state, file_content)


async def main() -> None:
    load_dotenv()
    token = os.environ.get("BOT_TOKEN")
    if not token:
        raise RuntimeError("–£–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è BOT_TOKEN")

    logging.basicConfig(level=logging.INFO)

    bot = Bot(token=token, parse_mode=ParseMode.HTML)
    dp = Dispatcher()

    dp.message.register(handle_start, CommandStart())
    dp.message.register(handle_cancel, Command(commands=["cancel"]))
    dp.message.register(handle_file, ConversionStates.waiting_file, F.document)
    dp.message.register(handle_file_link, ConversionStates.waiting_file, F.text)

    dp.message.register(handle_lines_per_file, ConversionStates.lines_per_file, F.text)

    dp.message.register(handle_output_mask, ConversionStates.output_mask, F.text)
    dp.message.register(handle_input_mask, ConversionStates.input_mask, F.text)

    await dp.start_polling(bot)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        pass
